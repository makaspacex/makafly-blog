---
title: HOG特征
lang: zh-CN
date: 2024-05-13 23:16:45
author: makaspacex
cover: https://cdn.jsdelivr.net/gh/makaspacex/PictureZone@main/picgo/v2-60eafba2db53f5cef77313b712a34315_b.jpg
tags:
---

# HOG特征

 **Author:** [jie luo]

 **Link:** [https://zhuanlan.zhihu.com/p/40960756]

> HOG全称**histogram of oriented gradients**.如果翻译成中文就是**方向梯度直方图** 。它可以用来表示图像的物体特征，因此能够检测出这类物体。

文章的内容将按照两部分进行，如果只对HOG的详细计算过程感兴趣可以直接跳到第二部分进行阅读。

  1. 论文笔记
  2. HOG实例讲解

## 一.论文笔记  

论文链接：[https://hal.inria.fr/file/index/docid/548512/filename/hog_cvpr2005.pdf](https://hal.inria.fr/file/index/docid/548512/filename/hog_cvpr2005.pdf)

这是一篇2005年CVPR论文，使用HOG+SVM做行人检测。

不过我都这篇文章的时候感觉不是很懂，对里面的细节都不是很清楚，可能是缺乏图像处理这一块的背景知识导致的。所以我只写一下文章的大概内容以及我的看法吧。

1.文章内容

这篇文章的主要贡献是提出了一个有效的提取行人特征方法，使用线性SVM模型作为分类器，对比了目前主流的特征描述子方法，做了大量的实验得出合适的系统参数，以及公布了一个更大的行人检测数据库。

![](https://cdn.jsdelivr.net/gh/makaspacex/PictureZone@main/picgo/v2-c37cf0789b9cf790d4b4afe514f9c906_b.jpg)  

这是HOG+SVM的工作流程。首先对输入的图片进行预处理，然后计算像素点的梯度值，然后形成梯度直方图，然后对blocks进行normalize，最后收集到HOG feature（其实是一行高维的vector）放到SVM里进行监督学习，从而实现行人的检测。

作者使用了两个数据集来测试，一个是MIT pedestrian database，还有一个是自己提出的测试集”INRIA“。其中INRIA数据集拥有更多更复杂的数据图像。

以SVM分类器作为基础，作者做了大量实验来对比不同特征提取方法，包括广义Haar wavelets/PCA-SIFT/Shape Contexts。实验表明，HOG具有很大的优越性。

作者做了大量的实验来选择系统参数，得到最好的系统性能表现。其中包括对图像进行Gamma normalization/gradient的计算方法/cell大小/block大小/bin大小/不同的SVM等作了对比实验。

2.我的感想

我很佩服作者提出的HOG这个想法。作者会想到对于行人检测来说，图像梯度是一个很重要的信息。利用图像梯度，就可以只关注边角信息，以此勾勒出的人的模样还是可以分辨出来。

同时，作者的实验也做得很充分，仅仅八页就重点讲解了特征提出的方法，而对SVM则粗描淡写。但是我还是看不懂HOG的提取计算过程，不过我通过查找其他资料，知道了HOG的细节。

**二. HOG实例讲解(以下所有的系统参数都是按照上述论文实验得出的最佳结果确定的)**

  1. **图像预处理**

包括伽马校正和灰度化。这是可选的步骤，因为实验证明做不做影响不大。伽马校正是减少光度对实验的影响。灰度化是将彩色图片变成灰度图。其实彩色图片也可以直接处理。不过是分别对三通道的颜色值进行梯度计算，最后选择梯度最大的那个。为简单起见，假设输入为灰度图，同时大小是64*128（这个大小是上面论文的大小，也可以自己确定不同的大小，但是实验效果就不能得到保证）。

  

**2.计算每一个像素点的梯度值，得到梯度图（规模和原图大小一样）**

![](https://cdn.jsdelivr.net/gh/makaspacex/PictureZone@main/picgo/v2-1d866ca3e02c8288b17c9b714f71f5f0_b.jpg)  

对于像素点A，要计算水平梯度和竖直梯度，如上图，水平梯度 $g_x$ =30-20=10,竖直梯度 $g_y$ =64-32=32.

那么总的梯度强度值g和梯度方向 $\theta$ 将按照以下公式计算：

$g=\sqrt{g_x^2+g_y^2}$

$\theta=arctan{\frac{g_x}{g_y}}$

梯度方向将会取绝对值，因此梯度方向的范围是0-180度。取绝对值的原因是这样效果更好。



**3.计算梯度直方图**

  

按照第二步的计算，每一个像素点都会有两个值：梯度强度/梯度方向。

现在就计算梯度直方图，这是一个关键步骤也是HOG能够work的原因。

梯度直方图是在一个8*8的cell里面计算的。那么在8*8的cell里面就会有8*8*2=128个值，2是包括了梯度强度和梯度方向。通过统计形成梯度直方图，128个值将会变成9个值，大大降低了计算量，同时又对光照等环境变化更加地robust。

首先，我将0-180度分成9个bins，分别是0，20，40...160。然后统计每一个像素点所在的bin。请看下图：

![](https://cdn.jsdelivr.net/gh/makaspacex/PictureZone@main/picgo/v2-8a48667c4af86625067fa656e27ac9e8_b.jpg)  

左上图是8*8的梯度方向值，右上图是8*8的梯度强度值，下图是9个bins。

先看两个蓝色圈圈。因为蓝圈的方向是80度，大小是2，所以该点就投给80这个bin；

再看两个红色圈圈。因为红色圈圈的方向是10，大小是4，因为10距离0点为10，距离20点为也为10，那么有一半的大小是投给0这个bin，还有一半的大小（即是2）投给20这个bin。

那么统计完64个点的投票数以后，每个bin就会得到一个数值，可以得到一个直方图，在计算机里面就是一个大小为9的数组。

![](https://cdn.jsdelivr.net/gh/makaspacex/PictureZone@main/picgo/v2-60eafba2db53f5cef77313b712a34315_b.jpg)  

**从上图可以看到，更多的点的梯度方向是倾向于0度和160度，也就是说这些点的梯度方向是向上或者向下，表明图像这个位置存在比较明显的横向边缘。因此HOG是对边角敏感的，由于这样的统计方法，也是对部分像素值变化不敏感的，所以能够适应不同的环境。**

  

**4\. 对16*16大小的block归一化**

归一化的目的是降低光照的影响。

归一化的方法是向量的每一个值除以向量的模长。

比如对于一个（128，64，32）的三维向量来说，模长是 $\sqrt{128^2+64^2+32^2}=146.64$

那么归一化后的向量变成了（0.87，0.43，0.22）

那么16*16大小的block是怎么来的？

请看下图：

![](https://cdn.jsdelivr.net/gh/makaspacex/PictureZone@main/picgo/v2-8b1272440a88b4ba792b59947c48d55a_b.gif)  

绿色方块是8*8大小的cell，蓝色方块就是由4个cell组成的block。作者提出要对block进行normalize。那么由于一个cell就会有大小为9的vector，四个cell就有36大小的vector。对block进行normalize就是对这大小为36的vector进行归一化。

而每一个block将按照上图篮框移动的方式进行迭代截取。

  

**5.得到HOG特征向量**

每一个16*16大小的block将会得到36大小的vector。那么对于一个64*128大小的图像，按照上图的方式提取block，将会有7个水平位置和15个竖直位可以取得，所以一共有7*15=105个block，所以我们整合所有block的vector，形成一个大的一维vector的大小将会是36*105=3780。

得到HOG特征向量，就可以用来可视化和分类了。对于这么大的HOG特征，SVM就排上用场了。

文章就写到这里，谢谢阅读。

reference：

1.[https://www.learnopencv.com/histogram-of-oriented-gradients/](https://www.learnopencv.com/histogram-of-oriented-gradients/)

2.[https://youtube.com/watch?v=0Zib1YEE4LU](https://youtube.com/watch?v=0Zib1YEE4LU)

